{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e232020-c812-45c3-86fa-aba19dcf8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40ce81ac-6c28-48be-9408-b96cedc7b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.kaiming_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c6a8df4-51cc-4768-b355-aa756ba62d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MP = os.path.join(os.pardir, 'metadata1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4149b468-21c6-4a8b-a83f-7374b6f5ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columname(PATH):\n",
    "    for i in list(os.listdir(PATH)):\n",
    "        file = os.path.join(PATH, i)\n",
    "        instance = np.load(file, allow_pickle=True)\n",
    "        column = []\n",
    "        column += ['z_mu_' + str(j) for j in range(len(instance['z_mu']))]\n",
    "        column += ['z_sig_' + str(j) for j in range(len(instance['z_sig']))]\n",
    "        column += ['vp' + str(j) for j in range(len(instance['vp']))]\n",
    "        column.append('y')\n",
    "        return column\n",
    "\n",
    "def load_meta(PATH):\n",
    "    total = []\n",
    "    for i in list(os.listdir(PATH)):\n",
    "        instance_list= []\n",
    "        file = os.path.join(PATH, i)\n",
    "        instance = np.load(file, allow_pickle=True)\n",
    "        instance_list.extend(instance['z_mu'])\n",
    "        instance_list.extend(instance['z_sig'])\n",
    "        instance_list.extend(instance['vp'])\n",
    "        instance_list.append(int(instance['y'].item()))\n",
    "        total.append(instance_list)\n",
    "    \n",
    "    total = np.array(total)\n",
    "    df = pd.DataFrame(data = total, columns=get_columname(PATH))\n",
    "    df = df.astype({'vp0':int, 'vp1':int, 'vp2':int, 'y':int})\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c5f853e6-8483-461f-b8af-9294f36f9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class CustomTrain(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, layers_list, activation=nn.ReLU(), dropout_list=None, batch_norm=True):\n",
    "        super(CustomTrain, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.layers_list = layers_list\n",
    "        self.activation = activation\n",
    "        self.dropout_list = dropout_list\n",
    "        self.batch_norm = batch_norm\n",
    "        self.net = []\n",
    "        self.b_list = []\n",
    "        if self.dropout_list:\n",
    "            self.dropout_list = [nn.Dropout(i) for i in self.dropout_list]\n",
    "        for i in range(len(self.layers_list)):\n",
    "            if i==0:\n",
    "                self.b_list.append(nn.BatchNorm1d(self.n_features))\n",
    "                self.net.append(nn.Linear(self.n_features, self.layers_list[i]))\n",
    "            else:\n",
    "                self.b_list.append(nn.BatchNorm1d(self.layers_list[i-1]))\n",
    "                self.net.append(nn.Linear(self.layers_list[i-1], self.layers_list[i]))\n",
    "        self.last_layer = nn.Linear(self.layers_list[-1], self.n_classes)\n",
    "        self.net = nn.ModuleList(self.net)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        for i, l in enumerate(self.net):\n",
    "            #print(i)\n",
    "            if self.batch_norm:\n",
    "                x = (self.b_list[i])(x)\n",
    "            x.to(device)\n",
    "            x = self.activation(l(x))\n",
    "            \n",
    "            if self.dropout_list:\n",
    "                x = (self.dropout_list[i])(x)\n",
    "            \n",
    "        x = self.last_layer(x)\n",
    "        if self.n_classes == 1:\n",
    "            x = torch.sigmoid(x)\n",
    "   \n",
    "        return x\n",
    "\n",
    "class datapaltas(Dataset):\n",
    "    def __init__(self, df, scale =True, y_idx=-1):\n",
    "        self.df = df\n",
    "        self.y_idx = y_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = (self.df.iloc[index,:self.y_idx]).values\n",
    "        X = X.astype(np.float64)\n",
    "        X = torch.from_numpy(X).float()\n",
    "        y = self.df.iloc[index,self.y_idx]\n",
    "        #print(y)\n",
    "        y = torch.Tensor([y]).long()\n",
    "        return {'x':X, 'y':y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c218eb20-ea5b-4e3d-bb81-c80505a96501",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "def train(data, model, ep = 120, save=False, prefix=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    idx_result = {}\n",
    "    a = datapaltas(df = data, y_idx=-1)\n",
    "    EPOCHS = ep\n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    ## y_idx -2\n",
    "    skf.get_n_splits(data, data.iloc[:,-1])\n",
    "    vec_train = np.array([train_ids for train_ids,_ in skf.split(data, data.iloc[:,-1])])\n",
    "    vec_test = np.array([test_ids for _,test_ids in skf.split(data, data.iloc[:,-1])])\n",
    "    acv, tav = [], []\n",
    "    foldn = 0\n",
    "    for train_ids, test_ids in zip(vec_train, vec_test):\n",
    "        acv_, tav_ = [], []\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                            a, \n",
    "                            batch_size=64, sampler=train_subsampler)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "                            a,\n",
    "                            batch_size=1, sampler=test_subsampler)\n",
    "\n",
    "        EPOCHS = ep\n",
    "        itt = tqdm(range(EPOCHS))\n",
    "        for i in itt:\n",
    "            loss_epoch = 0\n",
    "            acc_train, acc_test = 0.0, 0.0\n",
    "            model.train()\n",
    "            for sample in train_loader:\n",
    "                X, y = sample['x'], sample['y']\n",
    "                X, y = X.to(device), y.to(device).flatten()\n",
    "                y_pred = model(X)\n",
    "                #print(y_pred, y)\n",
    "                loss = criterion(y_pred, y)\n",
    "                acc = multi_acc(y_pred, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_epoch += loss.item()\n",
    "                acc_train += acc.item()\n",
    "                \n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for sample in test_loader:\n",
    "                    X_test, y_test = sample['x'], sample['y']\n",
    "                    X_test, y_test = X_test.to(device), y_test.to(device).flatten()\n",
    "                    print(model.training)\n",
    "                    y_hat = model(X_test)\n",
    "                    acc = multi_acc(y_hat, y_test)\n",
    "                    acc_test += acc.item()\n",
    "                \n",
    "            acv_.append(acc_test/len(test_loader))\n",
    "            tav_.append(acc_train/len(train_loader))\n",
    "            #print(acv_)\n",
    "            if save and (abs(acc_test/len(test_loader) - max(acv_)<1e-8)):\n",
    "                    if os.path.exists(os.path.join(os.curdir, prefix+\"model_fold_\"+str(foldn)+\".pth\")):\n",
    "                        os.remove(os.path.join(os.curdir, prefix+\"model_fold_\"+str(foldn)+\".pth\"))\n",
    "                    torch.save(model, os.path.join(os.curdir, prefix+\"model_fold_\"+str(foldn)+\".pth\"))\n",
    "                    itt.set_postfix({'epoch_model': i, 'best_acc':max(acv_)})\n",
    "            t1, t2 = acc_train/len(train_loader), acc_test/len(test_loader)\n",
    "            itt.set_description(f\"Acc train: {t1:.2f} Acc test: {t2:.2f}\")\n",
    "        acv.append(acv_)\n",
    "        tav.append(tav_)\n",
    "        \n",
    "\n",
    "        foldn += 1\n",
    "        model.apply(init_normal)\n",
    "        \n",
    "    acv = np.array(acv)\n",
    "    tav = np.array(tav)\n",
    "    idx_result['acc'] = np.mean(acv, axis = 0)\n",
    "    idx_result['acc_std'] = np.std(acv, axis=0)\n",
    "    idx_result['train_acc'] = np.mean(tav, axis=0)\n",
    "    return idx_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c5c48056-a5d0-4a7c-9f9c-270afd9d178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_meta(MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8a88f4cf-6434-4011-a882-e1720242d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTrain(\n",
       "  (activation): GELU()\n",
       "  (last_layer): Linear(in_features=256, out_features=788, bias=True)\n",
       "  (net): ModuleList(\n",
       "    (0): Linear(in_features=67, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelo = CustomTrain(67, 788, [128, 128, 256, 256, 256], nn.GELU(), batch_norm=True)\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c5f4a3f9-d886-40b4-b835-29454800ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\.conda\\envs\\paltas\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp/ipykernel_15048/4271564252.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  vec_train = np.array([train_ids for train_ids,_ in skf.split(data, data.iloc[:,-1])])\n",
      "C:\\Users\\LENOVO\\.conda\\envs\\paltas\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp/ipykernel_15048/4271564252.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  vec_test = np.array([test_ids for _,test_ids in skf.split(data, data.iloc[:,-1])])\n",
      "  0%|                                                                                           | 0/50 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 67])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15048/4236054538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'met1_v4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15048/4271564252.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, model, ep, save, prefix)\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                     \u001b[0macc_test\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\paltas\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15048/3797576175.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m#print(i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\paltas\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\paltas\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\paltas\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2278\u001b[0m         )\n\u001b[0;32m   2279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2280\u001b[1;33m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m     return torch.batch_norm(\n",
      "\u001b[1;32m~\\.conda\\envs\\paltas\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2246\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2248\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 67])"
     ]
    }
   ],
   "source": [
    "eo = train(a, modelo, ep=50, save=True, prefix='met1_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dea60d-620f-443b-a5ac-2c0e3d2c0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eo[\"acc\"])\n",
    "plt.plot(eo[\"train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eadd82b9-3d66-41e0-804f-4b6d4732ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU()\n",
      "Linear(in_features=256, out_features=788, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=67, out_features=1024, bias=True)\n",
      "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for child in model.children():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc938c-830c-4bab-8dca-c2e98e33adce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0e170ee7-045e-474c-8888-83bc65f694b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8590,  0.5250,  0.7132, -0.0781,  0.5314,  0.3811,  0.6054,  1.6083,\n",
       "          0.4533,  0.4299, -1.1930, -0.0554, -0.2127, -1.0761,  0.5811,  0.5002,\n",
       "          0.2879,  1.3363,  1.2084, -1.0590, -0.2013, -0.1151, -0.3977, -0.7007,\n",
       "          0.6692,  0.9484, -1.7068,  0.5066, -0.9476,  0.1339,  0.7815,  0.0863,\n",
       "         -0.4813,  0.1134, -0.0872, -1.5166, -1.5565,  2.3727,  1.3591,  0.6989,\n",
       "          0.7292,  0.9913, -0.1311, -0.2473, -1.3831,  0.7652, -0.2156,  0.8213,\n",
       "          0.0957, -0.5370, -0.2610,  0.3676, -0.2735,  2.1165,  0.9705, -1.2300,\n",
       "          0.6576,  1.2233, -0.5727,  0.8554,  0.6659, -0.4522, -0.3276, -0.3109,\n",
       "         -0.3851, -0.6309, -0.2510,  0.9572,  1.0285, -0.8394, -0.2947,  0.2623,\n",
       "         -1.6794, -0.2820, -1.6820, -0.0750,  0.3905, -0.7908,  0.0696, -0.7503,\n",
       "         -2.0633,  1.5216,  1.1269, -0.5935,  1.5394, -1.6033, -0.3636,  0.4839,\n",
       "         -0.8443,  0.9877,  0.2262,  0.6526, -0.5637,  0.3416, -1.4988,  0.9133,\n",
       "         -1.0327,  2.1566, -0.0413,  2.3540]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "m.eval()\n",
    "m(torch.randn(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03f1e5-215c-4f70-aa1e-6d714beccdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c95fb-5f2a-45f9-8f3d-0a27d2ec7c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fcaa4-ad7a-4b11-97b1-b9f8df6a782f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5ebac-4f36-41a1-b271-47cf706e0171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paltas",
   "language": "python",
   "name": "paltas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
